~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

original_height=160
original_width=320

top_crop=60
bottom_crop=20
left_crop=0
right_crop=0

resize_to_height=66
resize_to_width=200

angle_offset=0.2

batch_size=128

model_mode='nvidia-v2'

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

if model_mode == 'nvidia-v2':
    model=Sequential()
    drop_rate=0.5
    
    # Preprocess incoming data, centered around zero with small standard deviation 
    model.add(Lambda(lambda x: x/127.5-1.,input_shape=(original_height,original_width,3), name='norm'))
    
    # crop to remove the car hood and sky
    model.add(Cropping2D(cropping=((top_crop,bottom_crop),(left_crop,right_crop)),
                         data_format='channels_last',name='crop'))
    
    # resize to match the NVidia paper
    model.add(Lambda(tf_resize, name='resize'))
    
    ##### NVidia
    model.add(Conv2D(24,(5,5),strides=(2,2),name='conv1'))
    model.add(ELU(name='elu1'))
    model.add(Conv2D(36,(5,5),strides=(2,2),name='conv2'))
    model.add(ELU(name='elu2'))
    model.add(Conv2D(48,(5,5),strides=(2,2),name='conv3'))
    model.add(ELU(name='elu3'))
    
    model.add(Conv2D(64,(3,3),name='conv4'))
    model.add(ELU(name='elu4'))
    model.add(Conv2D(64,(3,3),name='conv5'))
    model.add(ELU(name='elu5'))
    
    model.add(Flatten(name='flatten'))
    
    model.add(Dense(100,name='dense1'))
    model.add(Dropout(drop_rate, name='drop1'))
    model.add(ELU(name='elu6'))
    model.add(Dense(50,name='dense2'))
    model.add(Dropout(drop_rate, name='drop2'))
    model.add(ELU(name='elu7'))
    model.add(Dense(10,name='dense3'))
    model.add(Dropout(drop_rate, name='drop3'))
    model.add(ELU(name='elu8'))
    
    model.add(Dense(1,name='output'))

    model.summary()

    lr=0.001
    optimizer=Adam(lr=lr)
    model.compile(loss='mse', optimizer=optimizer)

    save_to='model-nvidia-v2-005.h5'
    
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
norm (Lambda)                (None, 160, 320, 3)       0         
_________________________________________________________________
crop (Cropping2D)            (None, 80, 320, 3)        0         
_________________________________________________________________
resize (Lambda)              (None, 66, 200, 3)        0         
_________________________________________________________________
conv1 (Conv2D)               (None, 31, 98, 24)        1824      
_________________________________________________________________
elu1 (ELU)                   (None, 31, 98, 24)        0         
_________________________________________________________________
conv2 (Conv2D)               (None, 14, 47, 36)        21636     
_________________________________________________________________
elu2 (ELU)                   (None, 14, 47, 36)        0         
_________________________________________________________________
conv3 (Conv2D)               (None, 5, 22, 48)         43248     
_________________________________________________________________
elu3 (ELU)                   (None, 5, 22, 48)         0         
_________________________________________________________________
conv4 (Conv2D)               (None, 3, 20, 64)         27712     
_________________________________________________________________
elu4 (ELU)                   (None, 3, 20, 64)         0         
_________________________________________________________________
conv5 (Conv2D)               (None, 1, 18, 64)         36928     
_________________________________________________________________
elu5 (ELU)                   (None, 1, 18, 64)         0         
_________________________________________________________________
flatten (Flatten)            (None, 1152)              0         
_________________________________________________________________
dense1 (Dense)               (None, 100)               115300    
_________________________________________________________________
drop1 (Dropout)              (None, 100)               0         
_________________________________________________________________
elu6 (ELU)                   (None, 100)               0         
_________________________________________________________________
dense2 (Dense)               (None, 50)                5050      
_________________________________________________________________
drop2 (Dropout)              (None, 50)                0         
_________________________________________________________________
elu7 (ELU)                   (None, 50)                0         
_________________________________________________________________
dense3 (Dense)               (None, 10)                510       
_________________________________________________________________
drop3 (Dropout)              (None, 10)                0         
_________________________________________________________________
elu8 (ELU)                   (None, 10)                0         
_________________________________________________________________
output (Dense)               (None, 1)                 11        
=================================================================
Total params: 252,219
Trainable params: 252,219
Non-trainable params: 0
_________________________________________________________________

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

early_stopper=EarlyStopping(patience=5, verbose=1)
checkpointer=ModelCheckpoint(save_to, monitor='val_loss', verbose=1, save_best_only=True)

epochs = 100

history_object = model.fit_generator(generator=train_generator, 
                                     steps_per_epoch=len(train_samples) / batch_size, 
                                     validation_data=validation_generator,
                                     validation_steps=len(validation_samples) / batch_size,
                                     callbacks=[checkpointer, early_stopper],
                                     use_multiprocessing=True,
                                     epochs=epochs, 
                                     verbose=1)

model.save(save_to)

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Epoch 1/100
35/34 [==============================] - 41s 1s/step - loss: 0.0841 - val_loss: 0.0240

Epoch 00001: val_loss improved from inf to 0.02397, saving model to model-nvidia-v2-005.h5
Epoch 2/100
35/34 [==============================] - 32s 918ms/step - loss: 0.0358 - val_loss: 0.0213

Epoch 00002: val_loss improved from 0.02397 to 0.02127, saving model to model-nvidia-v2-005.h5
Epoch 3/100
35/34 [==============================] - 34s 969ms/step - loss: 0.0288 - val_loss: 0.0190

Epoch 00003: val_loss improved from 0.02127 to 0.01902, saving model to model-nvidia-v2-005.h5
Epoch 4/100
35/34 [==============================] - 33s 952ms/step - loss: 0.0254 - val_loss: 0.0183

Epoch 00004: val_loss improved from 0.01902 to 0.01829, saving model to model-nvidia-v2-005.h5
Epoch 5/100
35/34 [==============================] - 33s 943ms/step - loss: 0.0236 - val_loss: 0.0169

Epoch 00005: val_loss improved from 0.01829 to 0.01693, saving model to model-nvidia-v2-005.h5
Epoch 6/100
35/34 [==============================] - 34s 961ms/step - loss: 0.0216 - val_loss: 0.0157

Epoch 00006: val_loss improved from 0.01693 to 0.01573, saving model to model-nvidia-v2-005.h5
Epoch 7/100
35/34 [==============================] - 33s 941ms/step - loss: 0.0208 - val_loss: 0.0152

Epoch 00007: val_loss improved from 0.01573 to 0.01524, saving model to model-nvidia-v2-005.h5
Epoch 8/100
35/34 [==============================] - 34s 970ms/step - loss: 0.0194 - val_loss: 0.0171

Epoch 00008: val_loss did not improve from 0.01524
Epoch 9/100
35/34 [==============================] - 34s 972ms/step - loss: 0.0193 - val_loss: 0.0165

Epoch 00009: val_loss did not improve from 0.01524
Epoch 10/100
35/34 [==============================] - 34s 981ms/step - loss: 0.0182 - val_loss: 0.0146

Epoch 00010: val_loss improved from 0.01524 to 0.01462, saving model to model-nvidia-v2-005.h5
Epoch 11/100
35/34 [==============================] - 33s 931ms/step - loss: 0.0174 - val_loss: 0.0143

Epoch 00011: val_loss improved from 0.01462 to 0.01435, saving model to model-nvidia-v2-005.h5
Epoch 12/100
35/34 [==============================] - 34s 982ms/step - loss: 0.0170 - val_loss: 0.0143

Epoch 00012: val_loss improved from 0.01435 to 0.01426, saving model to model-nvidia-v2-005.h5
Epoch 13/100
35/34 [==============================] - 33s 942ms/step - loss: 0.0162 - val_loss: 0.0139

Epoch 00013: val_loss improved from 0.01426 to 0.01393, saving model to model-nvidia-v2-005.h5
Epoch 14/100
35/34 [==============================] - 34s 979ms/step - loss: 0.0159 - val_loss: 0.0140

Epoch 00014: val_loss did not improve from 0.01393
Epoch 15/100
35/34 [==============================] - 33s 943ms/step - loss: 0.0160 - val_loss: 0.0140

Epoch 00015: val_loss did not improve from 0.01393
Epoch 16/100
35/34 [==============================] - 34s 981ms/step - loss: 0.0155 - val_loss: 0.0142

Epoch 00016: val_loss did not improve from 0.01393
Epoch 17/100
35/34 [==============================] - 34s 964ms/step - loss: 0.0153 - val_loss: 0.0148

Epoch 00017: val_loss did not improve from 0.01393
Epoch 18/100
35/34 [==============================] - 34s 972ms/step - loss: 0.0151 - val_loss: 0.0138

Epoch 00018: val_loss improved from 0.01393 to 0.01384, saving model to model-nvidia-v2-005.h5
Epoch 19/100
35/34 [==============================] - 34s 972ms/step - loss: 0.0148 - val_loss: 0.0135

Epoch 00019: val_loss improved from 0.01384 to 0.01348, saving model to model-nvidia-v2-005.h5
Epoch 20/100
35/34 [==============================] - 34s 966ms/step - loss: 0.0143 - val_loss: 0.0138

Epoch 00020: val_loss did not improve from 0.01348
Epoch 21/100
35/34 [==============================] - 33s 937ms/step - loss: 0.0143 - val_loss: 0.0141

Epoch 00021: val_loss did not improve from 0.01348
Epoch 22/100
35/34 [==============================] - 33s 949ms/step - loss: 0.0144 - val_loss: 0.0142

Epoch 00022: val_loss did not improve from 0.01348
Epoch 23/100
35/34 [==============================] - 35s 997ms/step - loss: 0.0139 - val_loss: 0.0140

Epoch 00023: val_loss did not improve from 0.01348
Epoch 24/100
35/34 [==============================] - 32s 922ms/step - loss: 0.0141 - val_loss: 0.0138

Epoch 00024: val_loss did not improve from 0.01348
Epoch 00024: early stopping

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~